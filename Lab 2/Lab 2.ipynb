{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: MGM Speedway Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this lab you will get 20 minutes to create the model you will be racing with at the MGM Speedway. You can always train another model afterwards, but make good use of the time and resources to come up with a great model. From the Reinforcement learning page choose **Create model** and leave all hyperparameter settings as they are, and focus your time on the reward function. \n",
    "\n",
    "While you don't have to start training your model after 20 minutes, it is advisable to try get to a point where you can as training will take the better part of an hour and you want to ensure you get to the MGM Speedway with your model on your USB stick.\n",
    "\n",
    "Once your model training is completed, create a folder called \"models\" on your USB stick, download the model from the AWS DeepRacer console, and copy it to the models folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward Function Tips\n",
    "Tip 1: Start off looking at the advanced reward functions for inspiration. We provide a few examples below.\n",
    "Tip 2: Think carefully through the driving behavior you want to incentivize and consider the trade-offs. For example, you can penalize your car for going slow, but if all your car can do is go fast, it may not be the best at taking turns.\n",
    "\n",
    "Here are the variables you can use in your logic. \n",
    "Furthermore, the following three cells show examples of advanced reward functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Reward Function Variables](img/reward_vars.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advanced Reward Function 1\n",
    "def reward_function(on_track, x, y, distance_from_center, car_orientation, progress, steps, throttle, steering, track_width, waypoints, closest_waypoint):\n",
    "\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    import math\n",
    "\n",
    "    marker_1 = 0.1 * track_width\n",
    "    marker_2 = 0.25 * track_width\n",
    "    marker_3 = 0.5 * track_width\n",
    "\n",
    "    reward = 1e-3\n",
    "    if distance_from_center >= 0.0 and distance_from_center <= marker_1:\n",
    "        reward = 1\n",
    "    elif distance_from_center <= marker_2:\n",
    "        reward = 0.5\n",
    "    elif distance_from_center <= marker_3:\n",
    "        reward = 0.1\n",
    "    else:\n",
    "        reward = 1e-3  # likely crashed/ close to off track\n",
    "\n",
    "    # penalize reward if the car is steering way too much\n",
    "    ABS_STEERING_THRESHOLD = 0.5\n",
    "    if abs(steering) > ABS_STEERING_THRESHOLD:\n",
    "        reward *= 0.8\n",
    "\n",
    "    return float(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advanced Reward Function 2\n",
    "def reward_function(on_track, x, y, distance_from_center, car_orientation, progress, steps, throttle, steering, track_width, waypoints, closest_waypoint):\n",
    "\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    import math\n",
    "\n",
    "    marker_1 = 0.1 * track_width\n",
    "    marker_2 = 0.25 * track_width\n",
    "    marker_3 = 0.5 * track_width\n",
    "\n",
    "    reward = 1e-3\n",
    "    if distance_from_center >= 0.0 and distance_from_center <= marker_1:\n",
    "        reward = 1\n",
    "    elif distance_from_center <= marker_2:\n",
    "        reward = 0.5\n",
    "    elif distance_from_center <= marker_3:\n",
    "        reward = 0.1\n",
    "    else:\n",
    "        reward = 1e-3  # likely crashed/ close to off track\n",
    "\n",
    "    # penalize reward for the car taking slow actions\n",
    "    THROTTLE_THRESHOLD = 0.5\n",
    "    if throttle < THROTTLE_THRESHOLD:\n",
    "        reward *= 0.8\n",
    "\n",
    "    return float(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advanced Reward Function 3\n",
    "#Bonus Advanced Reward Function 3\n",
    "def reward_function(on_track, x, y, distance_from_center, car_orientation, progress, steps, throttle, steering, track_width, waypoints, closest_waypoint):\n",
    "\n",
    "    reward = 1e-3\n",
    "    if distance_from_center >= 0.0 and distance_from_center <= 0.03:\n",
    "        reward = 1.0\n",
    "    \n",
    "    # add steering penalty\n",
    "    if abs(steering) > 0.5:\n",
    "        reward *= 0.80\n",
    "\n",
    "    # add throttle penalty\n",
    "    if throttle < 0.5:\n",
    "        reward *= 0.80\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
